{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381487f2",
   "metadata": {},
   "source": [
    "# Lecture 4.3 Data Preprocessing - Part 2 & Data Visualization\n",
    "\n",
    "dataset = https://www.kaggle.com/datasets/yufengdev/bbc-fulltext-and-category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2399df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018cb0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>bangkok film festival battles on organisers of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>tech</td>\n",
       "      <td>pc photo printers challenge pros home printed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>tech</td>\n",
       "      <td>digital guru floats sub-$100 pc nicholas negro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>politics</td>\n",
       "      <td>no more concessions  on terror charles clarke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>sport</td>\n",
       "      <td>mcclaren targets champions league middlesbroug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>sky takes over oscar night mantle sky has sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>sport</td>\n",
       "      <td>candela completes bolton switch bolton boss sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>business</td>\n",
       "      <td>brazil plays down varig rescue the brazilian g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>business</td>\n",
       "      <td>indonesians face fuel price rise indonesia s g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>business</td>\n",
       "      <td>s&amp;n extends indian beer venture the uk s bigge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "364   entertainment  bangkok film festival battles on organisers of...\n",
       "1723           tech  pc photo printers challenge pros home printed ...\n",
       "1463           tech  digital guru floats sub-$100 pc nicholas negro...\n",
       "817        politics  no more concessions  on terror charles clarke ...\n",
       "645           sport  mcclaren targets champions league middlesbroug...\n",
       "350   entertainment  sky takes over oscar night mantle sky has sign...\n",
       "560           sport  candela completes bolton switch bolton boss sa...\n",
       "1401       business  brazil plays down varig rescue the brazilian g...\n",
       "1241       business  indonesians face fuel price rise indonesia s g...\n",
       "238        business  s&n extends indian beer venture the uk s bigge..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_location = '/Users/christopherreid/My Drive (christopherreid@arizona.edu)/Classes/6. Summer 2023/CSC 380 - Principles of Data Science/Lectures/Jupyter Notebooks/bbc-text.csv'\n",
    "articles_df = pd.read_csv(dataset_location)\n",
    "articles_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a058c8",
   "metadata": {},
   "source": [
    "**Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c497edea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3843b40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count\n",
       "category            \n",
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df['category'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dcf67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bombardier chief to leave company shares in train and plane-making giant bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.  paul tellier  who was also bombardier s president  left the company amid an ongoing restructuring. laurent beaudoin  part of the family that controls the montreal-based firm  will take on the role of ceo under a newly created management structure. analysts said the resignations seem to have stemmed from a boardroom dispute. under mr tellier s tenure at the company  which began in january 2003  plans to cut the worldwide workforce of 75 000 by almost a third by 2006 were announced. the firm s snowmobile division and defence services unit were also sold and bombardier started the development of a new aircraft seating 110 to 135 passengers.  mr tellier had indicated he wanted to stay at the world s top train maker and third largest manufacturer of civil aircraft until the restructuring was complete. but bombardier has been faced with a declining share price and profits. earlier this month the firm said it earned $10m (Â£19.2m) in the third quarter  down from a profit of $133m a year ago.  i understand the board s concern that i would not be there for the long-term and the need to develop and execute strategies  and the need to reshape the management structure at this time   mr tellier said in a statement on monday. bombardier said restructuring plans drawn up by mr tellier s would continue to be implemented. shares in bombardier lost 65 canadian cents or 25% on the news to 1.90 canadian dollars before rallying to 2.20 canadian dollars.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample()['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f859a",
   "metadata": {},
   "source": [
    "Sometimes Language Detection is necessary\n",
    "\n",
    "**Capitalization/Lower Case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa67892",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['lower_case'] = articles_df['text'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c403c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imf  cuts  german growth estimate the international monetary fund is to cut its 2005 growth forecast for the german economy from 1.8% to 0.8%  the financial times deutschland reported.  the imf will also reduce its growth estimate for the 12-member eurozone economy from 2.2% to 1.6%  the newspaper reported. the german economy has been faltering  with unemployment levels rising to a seventy-year high of 5.2 million. its sluggish performance continues to hamper the entire eurozone.  the imf s draft world economic outlook - due to be published in april - would point to a marked deterioration in germany s economy  the ft report said.  in september  the imf had said that german growth for the current year would be 1.8%. the imf has also revised eurozone forecasts  the paper said  taking into account high oil prices  the strength of the euro and weak demand in many of the world s leading economies. europe s economic difficulties have been highlighted by the organisation for economic co-operation and development  which argued in a report published on tuesday that the continent could only achieve us living standards by freeing up its labour markets.  the eurozone does not look like it has a self-sustaining recovery   james carrick  an economist with abn amro  told the newspaper.  it is too dependant on the rest of the world.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample()['lower_case'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68099a",
   "metadata": {},
   "source": [
    "- Replace the Unicode character with equivalent ASCII character or remove them\n",
    "- Replace the entity refereneces with their actual symbols or removing HTML tags\n",
    "- Replace the types, slang, acronyms or informal abbreviations - depends on different situations or main topics of the NLP such as finance or medical topics\n",
    "- List out all the hashtags/ usernames then replace with equivalent words\n",
    "- Replace the moticon/ emoji with equivalent word meaning such as ':)' with 'smile, or dropping emojis entirely\n",
    "- Spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db0b5e",
   "metadata": {},
   "source": [
    "**Remove punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c96f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6398db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey where are you'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'hey! where are you!?'\n",
    "# Replaces all punctuation (!?.) with an empty string ('')\n",
    "sample_processed = sample.translate(str.maketrans ('','',string.punctuation))\n",
    "sample_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c90314",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['punct_removed'] = articles_df['lower_case'].apply(lambda doc: doc.translate(str.maketrans ('','',string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafab938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gm  ford cut output as sales fall us car firms general motors gm and ford have been forced to cut production in the face of falling car sales  us sales at gm sank 127 in february compared to a year ago while ford sales dropped 3 as foreign rivals took a bigger share of the market meanwhile  asian carmakers fared well  toyota sales jumped 11 while rival nissan notched up a 10 increase overall sales across the industry also fell to 125 million vehicles from 127 million a year earlier  gm and ford blamed high fuel prices for low sales of big trucks and gasguzzling sports utility vehicles suvs  the vehicles that provide the biggest profits  gm added that us truck sales fell 9 in february while car business tumbled 17  however it did acknowledge that some new products  such as the pontiac g6 and chevrolet cobalt  had put in solid performances  the calendar year is starting off slower than expected  both for gm and the industry   said mark laneve  gm s vice president for north american sales  service and marketing the slump in sales prompted the group to cut production in north america by 3  it has already reduced output by around 9 in the face of growing stockpiles meanwhile  ford which posted its ninth consecutive drop in monthly us sales  said it was cutting firstquarter north american production by another 10 000 vehicles  or 12 chrysler  the us unit of germany s daimlerchrysler  was the only detroit based automaker to boast an increase in market share during the month  with sales rising 8  but america s loss was its foreign rivals  gain as they continued to nibble away at the us market while japan s top car maker toyota and nissan saw sales accelerate  even the smaller suzuki motor corp snapped up a more business with sales improving 176 on a year ago in 2003  the firm launched an ambitious plan to triple us sales by 2007 as it seeks to become a bigger player in the asian assault on the us market korea s hyundai was another big gainer  turning in a 19 surge in february sales toyota put its rise in sales down to strong results for its redesigned avalon sedan and a 120 surge in sales of its gaselectric prius hybrid midsize sedan as petrolprice conscious consumers looked to vehicles that were cheaper to run  as gas prices continue their upward march  fuel efficiency catches the public eye   jim press  vice president and chief operating officer of toyota s us sales arm  said in a statement'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample()['punct_removed'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fbd6a",
   "metadata": {},
   "source": [
    "**Tokenise**\n",
    "\n",
    "Source = https://github.com/AmalM7/NLP-Stuff/blob/main/Tokenization_in_NLP.ipynb\n",
    "\n",
    "A token is an instance of a sequence of characters in some particular document that are grouped together as a userfull semantic unit for processing.\n",
    "\n",
    "ie. A tokenis a meaningful chunk of text that we use to process and understand the information ina document. It can be a word, a phrase, or even a symbol or punctuation mark. Tokens help us break down the text into smaller pieces so that we can analyze and work with it more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36676061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (8.1.4)\r\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (1.3.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (2023.6.3)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (4.65.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/christopherreid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Mr. O'Neill thinks that the boys' stories about Chile's capital aren't amusing ðŸ™ƒ\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import (word_tokenize,\n",
    "                          sent_tokenize,\n",
    "                          TreebankWordTokenizer,\n",
    "                          wordpunct_tokenize,\n",
    "                          TweetTokenizer,\n",
    "                          MWETokenizer)\n",
    "\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "mwet_tokenizer = MWETokenizer()\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "text = \"Mr. O'Neill thinks that the boys' stories about Chile's capital aren't amusing ðŸ™ƒ\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10696f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word_tokenise: \n",
      " ['Mr.', \"O'Neill\", 'thinks', 'that', 'the', 'boys', \"'\", 'stories', 'about', 'Chile', \"'s\", 'capital', 'are', \"n't\", 'amusing', 'ðŸ™ƒ'] \n",
      "Length : 16\n",
      "\n",
      "Word Punct Tokeniser : \n",
      " ['Mr', '.', 'O', \"'\", 'Neill', 'thinks', 'that', 'the', 'boys', \"'\", 'stories', 'about', 'Chile', \"'\", 's', 'capital', 'aren', \"'\", 't', 'amusing', 'ðŸ™ƒ'] \n",
      "Length : 21\n",
      "\n",
      "Tree Bank : ['Mr.', \"O'Neill\", 'thinks', 'that', 'the', 'boys', \"'\", 'stories', 'about', 'Chile', \"'s\", 'capital', 'are', \"n't\", 'amusing', 'ðŸ™ƒ'] \n",
      "Length : 16\n",
      "\n",
      "Tweet Tokenizer : ['Mr', '.', \"O'Neill\", 'thinks', 'that', 'the', 'boys', \"'\", 'stories', 'about', \"Chile's\", 'capital', \"aren't\", 'amusing', 'ðŸ™ƒ'] \n",
      "Length : 15\n",
      "\n",
      "MWE Tokenizer : ['Mr.', \"O'Neill\", 'thinks', 'that', 'the', 'boys', \"'\", 'stories', 'about', 'Chile', \"'s\", 'capital', 'are', \"n't\", 'amusing', 'ðŸ™ƒ'] \n",
      "Length : 16\n"
     ]
    }
   ],
   "source": [
    "print('Word_tokenise: \\n', word_tokenize(text), '\\nLength :', len(word_tokenize(text)))\n",
    "print('\\nWord Punct Tokeniser : \\n', wordpunct_tokenize(text), '\\nLength :', len(wordpunct_tokenize(text)))\n",
    "print('\\nTree Bank :', treebank_tokenizer.tokenize(text), '\\nLength :', len(treebank_tokenizer.tokenize(text)))\n",
    "print('\\nTweet Tokenizer :', tweet_tokenizer.tokenize(text), '\\nLength :', len(tweet_tokenizer.tokenize(text)))\n",
    "print('\\nMWE Tokenizer :', mwet_tokenizer.tokenize(word_tokenize(text)), '\\nLength :', len(mwet_tokenizer.tokenize(word_tokenize(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a36ab385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e55463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['tokenized'] = articles_df['punct_removed'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8477070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['ericsson', 'sees', 'earnings', 'improve', 'telecoms', 'equipment', 'supplier', 'ericsson', 'has', 'posted', 'a', 'rise', 'in', 'fourth', 'quarter', 'profits', 'thanks', 'to', 'clients', 'like', 'deutsche', 'telekom', 'upgrade', 'their', 'networks', 'operating', 'profit', 'in', 'the', 'three', 'months', 'to', '31', 'december', 'was', '95bn', 'kronor', 'Â£722m', '13bn', 'against', '63bn', 'kronor', 'last', 'year', 'shares', 'tumbled', 'however', 'as', 'the', 'company', 'reported', 'a', 'profit', 'margin', 'of', '456', 'less', 'than', 'the', '473', 'forecast', 'by', 'analysts', 'and', 'down', 'from', '471', 'in', 'the', 'third', 'quarter', 'ericsson', 'shares', 'dropped', '59', 'to', '207', 'kronor', 'in', 'early', 'trading', 'on', 'thursday', 'however', 'the', 'company', 'remained', 'optimistic', 'about', 'its', 'earnings', 'outlook', 'after', 'sales', 'in', 'the', 'fourth', 'quarter', 'rose', '9', 'to', '394bn', 'kronor', 'longterm', 'growth', 'drivers', 'of', 'the', 'industry', 'remain', 'solid', 'ericsson', 'said', 'in', 'a', 'statement', 'chief', 'executive', 'carlhenric', 'svanberg', 'explained', 'that', 'about', '27', 'of', 'the', 'world', 's', 'population', 'now', 'has', 'access', 'to', 'mobile', 'communications', 'this', 'is', 'exciting', 'for', 'a', 'company', 'with', 'a', 'vision', 'of', 'an', 'allcommunicating', 'world', 'he', 'added', 'mr', 'svanberg', 'however', 'warned', 'that', 'the', 'extra', 'demand', 'that', 'had', 'driven', '2004', 'sales', 'had', 'already', 'dissipated', 'and', 'it', 'was', 'business', 'as', 'usual', 'he', 'added', 'that', 'sales', 'in', 'the', 'first', 'three', 'months', 'of', '2005', 'would', 'be', 'subject', 'to', 'normal', 'seasonality', 'for', 'the', 'whole', 'of', '2004', 'ericsson', 'returned', 'a', 'net', 'profit', 'of', '19bn', 'kronor', 'compared', 'with', 'a', 'loss', 'of', '108bn', 'kronor', 'in', '2003', 'sales', 'climbed', 'to', '1319', 'billion', 'kronor', 'from', '1177bn', 'kronor', 'in', '2003'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample()['tokenized'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297fc20",
   "metadata": {},
   "source": [
    "**Remove Stop Words (or/and Frequent words/ Rare words)**\n",
    "\n",
    "Stop words are the most common words in any languages (like articles, prepositions, pronouns, conjunctions, etc) and does not add much information to the text. Examples of a few stop words in English are 'the', 'a', 'an', 'so', 'what'.\n",
    "\n",
    "It can go wrong too.\n",
    "- Mark reported to the CEO: Mark reported CEO\n",
    "- Suzanne rpoerted as the CEO to the board: Suzanned reported CEO board\n",
    "\n",
    "In your NLP pipeline, you might create 4-grams such as reported to the CEO and reported as the CEO. If you removed the stop words from the 4-grams, both examples would be reduced to 'reported CEO', and you would lack the information about the professional hierarchy. In the first example, Mark could have been an assistant to the CEO, whereas in the second example Suzanne was the CEO reporting to the board. Unfortunately, retaining the stop words within your pipeline creates another problem: it increases the length of the n-grams required ot make use of these connections formed by the otherwise meaningless stop words. This issue forces us to retain at least 4-grams if you want to avoid ambiguity of the human resources example. designing a filter for stop words depends on your particular application.\n",
    "\n",
    "Source: https://www.manning.com/books/natural-language-processing-in-action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce98d8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christopherreid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "709a611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4c7c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you'll\", 'during', 'few', 'ain', 'our', 'we', 'over', 'a', 'it', 'how', 'don', \"mustn't\", 'each', \"she's\", 'before', 'my', 'further', 'because', \"don't\", 'ma', 'themselves', 'at', 'has', 'off', \"didn't\", 'some', 'is', 've', 'that', 'me', 'these', 'for', 'shouldn', 'out', 'there', 'their', 'than', 'an', 'where', 'does', 'between', \"couldn't\", \"isn't\", 'itself', 'above', 'were', 'against', 'didn', \"mightn't\", \"wasn't\", 'your', 'he', \"doesn't\", \"hadn't\", 'will', 'you', \"weren't\", 'yourselves', 'other', 'which', \"won't\", 'himself', 'doesn', 'more', 'couldn', 'on', 'any', 'did', 'under', 'them', \"that'll\", 'by', 'own', 'isn', 'him', 'no', 'aren', 'while', 'hasn', 'do', 'through', 'was', \"you're\", 'won', 'what', 'now', 'd', 'her', \"haven't\", 'weren', 't', 'yours', 'of', 'again', 'should', 'be', 'up', 'ourselves', 'here', 'too', 'she', \"shouldn't\", 'doing', 'been', 'wasn', 'nor', \"aren't\", 'to', 'll', 'hadn', 'myself', 'why', 'those', 'his', \"you'd\", 'or', 'not', 'and', 'am', 'm', 'o', \"wouldn't\", 'until', 'only', 'who', 'shan', 'y', 'into', \"needn't\", 're', 'the', 'mustn', 'ours', 'from', 'having', 'all', 'its', 'i', 'yourself', 'so', 'same', 'this', 'below', 'hers', 'being', 'down', 'mightn', 'in', 's', \"shan't\", 'with', 'about', 'most', 'needn', 'if', 'then', \"it's\", 'theirs', 'have', 'such', \"you've\", 'once', 'herself', \"should've\", 'wouldn', 'are', 'haven', 'both', 'when', 'very', 'they', \"hasn't\", 'but', 'after', 'just', 'had', 'as', 'whom', 'can'}\n"
     ]
    }
   ],
   "source": [
    "stopwords_eng = set(stopwords.words('english'))\n",
    "print(stopwords_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7266f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['stopwords_removed'] = articles_df['tokenized'].apply(lambda doc: [word for word in doc if word not in stopwords_eng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c2dcf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['arsenal', 'penalties', 'arsenal', 'win', '42', 'penalties', 'spanish', 'goalkeeper', 'saved', 'alan', 'quinn', 'jon', 'harley', 'arsenal', 'sealed', 'quarterfinal', 'trip', 'bolton', '42', 'victory', 'penalties', 'lauren', 'patrick', 'vieira', 'freddie', 'ljungberg', 'ashley', 'cole', 'scored', 'arsenal', 'andy', 'gray', 'phil', 'jagielka', 'target', 'blades', 'michael', 'tonge', 'harley', 'wasted', 'chances', 'underdogs', 'paddy', 'kenny', 'inspired', 'keep', 'arsenal', 'bay', 'arsenal', 'stripped', 'attacking', 'talent', 'thierry', 'henry', 'dennis', 'bergkamp', 'partnered', '17yearold', 'italian', 'striker', 'arturo', 'lupoli', 'ljungberg', 'front', 'revamped', 'arsenal', 'lineup', 'almost', 'goal', 'behind', 'within', 'seconds', 'tonge', 'wasted', 'glorious', 'chance', 'gray', 'ran', 'free', 'right', 'flank', 'cross', 'left', 'tonge', 'simplest', 'chances', 'blazed', 'top', 'six', 'yards', 'arsenal', 'barely', 'seen', 'attacking', 'force', 'opening', '45', 'minutes', 'although', 'ljungberg', 'turned', 'halfchance', 'wide', 'good', 'work', 'cesc', 'fabregas', 'arsene', 'wenger', 'introduced', 'quincy', 'owusuabeyie', 'ineffective', 'lupoli', 'halftime', 'pacy', 'dutch', 'youngster', 'immediate', 'impact', 'ran', 'clear', 'good', 'work', 'mathieu', 'flamini', 'finish', 'tame', 'kenny', 'saved', 'easily', 'owusuabeyie', 'fired', 'testing', 'cross', 'met', 'fabregas', 'needed', 'desperate', 'clearance', 'kenny', 'legs', 'save', 'blades', 'arsenal', 'totally', 'dominant', 'desperately', 'unlucky', 'take', 'lead', '62', 'minutes', 'fabregas', 'crashed', 'rising', 'drive', 'bar', '20', 'yards', 'took', 'brilliant', 'tackle', 'jagielka', 'deny', 'ljungberg', 'poised', 'strike', 'arsenal', 'continued', 'press', 'kenny', 'called', 'action', 'eight', 'minutes', 'left', 'diving', 'low', 'clutch', 'another', 'closerange', 'effort', 'fabregas', 'neil', 'warnock', 'side', 'almost', 'snatched', 'victory', 'dying', 'seconds', 'derek', 'geary', 'cross', 'found', 'harley', 'far', 'post', 'diving', 'header', 'brilliantly', 'turned', 'almunia', 'owusuabeyie', 'pace', 'causing', 'sorts', 'problems', 'blades', 'extratime', 'began', 'another', 'surging', 'run', 'penalty', 'area', 'almost', 'set', 'chance', 'ljungberg', 'pascal', 'cygan', 'missed', 'arsenal', 'best', 'chance', '106', 'minutes', 'blazing', 'across', 'face', 'goal', 'unmarked', 'far', 'post', 'arsenal', 'sent', 'jeremie', 'aliadiere', 'seven', 'minutes', 'extratime', 'left', 'almost', 'broke', 'deadlock', 'first', 'touch', 'kolo', 'toure', 'misplaced', 'freekick', 'landed', 'feet', 'kenny', 'blocked', 'tight', 'angle', 'arsenal', 'laid', 'siege', 'sheffield', 'united', 'goal', 'dying', 'minutes', 'somehow', 'held', 'force', 'penalties', 'almunia', 'arsenal', 'hero', 'another', 'brave', 'blades', 'cup', 'campaign', 'came', 'losing', 'end', 'kenny', 'geary', 'morgan', 'bromby', 'harley', 'liddell', 'montgomery', 'jagielka', 'thirlwell', 'tonge', 'quinn', '97', 'gray', 'subs', 'used', 'francis', 'kabba', 'shaw', 'haystead', 'morgan', 'almunia', 'lauren', 'cygan', 'senderos', 'cole', 'fabregas', 'toure', '90', 'vieira', 'flamini', 'aliadiere', '113', 'clichy', 'lupoli', 'owusuabeyie', '45', 'ljungberg', 'subs', 'used', 'eboue', 'taylor', 'clichy', 'lauren', 'senderos', '27', '595', 'p', 'dowd', 'staffordshire'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample()['stopwords_removed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28fb210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after tokenisation :  441\n",
      "Length after stopwords are removed :  234\n"
     ]
    }
   ],
   "source": [
    "sample_df = articles_df.sample()\n",
    "print('Length after tokenisation : ', len(sample_df['tokenized'].values[0]))\n",
    "print('Length after stopwords are removed : ', len(sample_df['stopwords_removed'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277e71e",
   "metadata": {},
   "source": [
    "**Stemming**\n",
    "\n",
    "The process of removing affixes or changing affixes or getting to the root words.\n",
    "\n",
    "Ex:\n",
    "- run, running, runs => run\n",
    "- programming, programmer, programs => program\n",
    "\n",
    "There are multiple stemming algorithms, but we will use Snowball (Porter2) Stemming Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7159ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9b725ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['snowball_stemmer'] = articles_df['stopwords_removed'].apply(lambda doc: [stemmer.stem(word) for word in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37d5955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['power', 'people', 'says', 'hp', 'digital', 'revolution', 'focused', 'letting', 'people', 'tell', 'share', 'stories', 'according', 'carly', 'fiorina', 'chief', 'technology', 'giant', 'hewlett', 'packard', 'job', 'firms', 'hp', 'said', 'speech', 'consumer', 'electronics', 'show', 'ces', 'ensure', 'digital', 'physical', 'worlds', 'fully', 'converged', 'said', 'goal', '2005', 'make', 'people', 'centre', 'technology', 'ces', 'showcases', '50', '000', 'new', 'gadgets', 'hitting', 'shelves', '2005', 'techfest', 'largest', 'kind', 'world', 'runs', '6', '9', 'january', 'digital', 'revolution', 'democratisation', 'technology', 'experiences', 'makes', 'possible', 'told', 'delegates', 'revolution', 'always', 'giving', 'power', 'people', 'added', 'real', 'story', 'digital', 'revolution', 'new', 'products', 'millions', 'experiences', 'made', 'possible', 'stories', 'millions', 'tell', 'part', 'giving', 'people', 'control', 'freeing', 'content', 'images', 'video', 'music', 'crucial', 'effort', 'make', 'devices', 'speak', 'better', 'content', 'easily', 'transferred', 'one', 'device', 'digital', 'camera', 'others', 'portable', 'media', 'players', 'lot', 'work', 'still', 'needs', 'done', 'however', 'sort', 'compatibility', 'issues', 'standards', 'within', 'technology', 'industry', 'gadgets', 'work', 'seamlessly', 'said', 'ms', 'fiorina', 'talk', 'also', 'touted', 'way', 'technology', 'designed', 'focus', 'lifestyle', 'fashion', 'personalisation', 'something', 'sees', 'key', 'people', 'want', 'special', 'guest', 'singer', 'gwen', 'stefani', 'joined', 'onstage', 'promote', 'range', 'hp', 'digital', 'cameras', 'ms', 'stefani', 'helped', 'design', 'heavily', 'influenced', 'japanese', 'youth', 'culture', 'digital', 'cameras', 'due', 'go', 'sale', 'us', 'summer', 'based', 'hp', '607', 'model', 'emphasis', 'personalisation', 'lifestyle', 'big', 'theme', 'year', 'ces', 'tiny', 'wearable', 'mp3', 'players', 'every', 'turn', 'rainbow', 'hues', 'giving', 'colour', 'everything', 'ms', 'fiorina', 'also', 'announced', 'hp', 'working', 'nokia', 'launch', 'visual', 'radio', 'service', 'mobiles', 'would', 'launch', 'europe', 'early', 'year', 'service', 'let', 'people', 'listen', 'radio', 'mobiles', 'download', 'relevant', 'content', 'like', 'track', 'ringtone', 'simultaneously', 'service', 'designed', 'make', 'mobile', 'radio', 'interactive', 'among', 'new', 'products', 'showcased', 'digital', 'media', 'hub', 'big', 'upgrade', 'hp', 'digital', 'entertainment', 'centre', 'coming', 'autumn', 'us', 'box', 'networked', 'highdefinition', 'tv', 'cable', 'settop', 'box', 'digital', 'video', 'recorder', 'dvd', 'recorder', 'removable', 'hard', 'drive', 'cartridge', 'memory', 'card', 'slots', 'light', 'scribe', 'labelling', 'software', 'lets', 'people', 'design', 'print', 'customised', 'dvd', 'labels', 'covers', 'designed', 'contain', 'household', 'digital', 'media', 'prerecorded', 'tv', 'shows', 'pictures', 'videos', 'music', 'managed', 'one', 'place', 'hub', 'reflects', 'increasing', 'move', 'rebox', 'pc', 'work', 'part', 'key', 'centres', 'entertainment', 'research', 'suggests', '258', 'million', 'images', 'saved', 'shared', 'every', 'day', 'equating', '94', 'billion', 'year', 'eighty', 'per', 'cent', 'remain', 'cameras', 'media', 'hubs', 'designed', 'encourage', 'people', 'organise', 'one', 'box', 'ms', 'fiorina', 'one', 'several', 'keynote', 'speakers', 'also', 'included', 'microsoft', 'chief', 'bill', 'gates', 'set', 'major', 'technology', 'companies', 'think', 'people', 'technologies', 'gadgets', 'next', '12', 'months', 'separate', 'announcement', 'keynote', 'speech', 'ms', 'fiorina', 'said', 'hp', 'would', 'partnering', 'mtv', 'replace', 'year', 'mtv', 'asia', 'music', 'award', 'mtv', 'asia', 'aid', 'held', 'bangkok', '3', 'february', 'aimed', 'helping', 'raise', 'money', 'asian', 'tsunami', 'disaster']\n"
     ]
    }
   ],
   "source": [
    "example = articles_df.sample()[['stopwords_removed', 'snowball_stemmer']].values.tolist()\n",
    "print(example[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "346391c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['power', 'peopl', 'say', 'hp', 'digit', 'revolut', 'focus', 'let', 'peopl', 'tell', 'share', 'stori', 'accord', 'carli', 'fiorina', 'chief', 'technolog', 'giant', 'hewlett', 'packard', 'job', 'firm', 'hp', 'said', 'speech', 'consum', 'electron', 'show', 'ce', 'ensur', 'digit', 'physic', 'world', 'fulli', 'converg', 'said', 'goal', '2005', 'make', 'peopl', 'centr', 'technolog', 'ce', 'showcas', '50', '000', 'new', 'gadget', 'hit', 'shelv', '2005', 'techfest', 'largest', 'kind', 'world', 'run', '6', '9', 'januari', 'digit', 'revolut', 'democratis', 'technolog', 'experi', 'make', 'possibl', 'told', 'deleg', 'revolut', 'alway', 'give', 'power', 'peopl', 'ad', 'real', 'stori', 'digit', 'revolut', 'new', 'product', 'million', 'experi', 'made', 'possibl', 'stori', 'million', 'tell', 'part', 'give', 'peopl', 'control', 'free', 'content', 'imag', 'video', 'music', 'crucial', 'effort', 'make', 'devic', 'speak', 'better', 'content', 'easili', 'transfer', 'one', 'devic', 'digit', 'camera', 'other', 'portabl', 'media', 'player', 'lot', 'work', 'still', 'need', 'done', 'howev', 'sort', 'compat', 'issu', 'standard', 'within', 'technolog', 'industri', 'gadget', 'work', 'seamlessli', 'said', 'ms', 'fiorina', 'talk', 'also', 'tout', 'way', 'technolog', 'design', 'focu', 'lifestyl', 'fashion', 'personalis', 'someth', 'see', 'key', 'peopl', 'want', 'special', 'guest', 'singer', 'gwen', 'stefani', 'join', 'onstag', 'promot', 'rang', 'hp', 'digit', 'camera', 'ms', 'stefani', 'help', 'design', 'heavili', 'influenc', 'japanes', 'youth', 'cultur', 'digit', 'camera', 'due', 'go', 'sale', 'us', 'summer', 'base', 'hp', '607', 'model', 'emphasi', 'personalis', 'lifestyl', 'big', 'theme', 'year', 'ce', 'tini', 'wearabl', 'mp3', 'player', 'everi', 'turn', 'rainbow', 'hue', 'give', 'colour', 'everyth', 'ms', 'fiorina', 'also', 'announc', 'hp', 'work', 'nokia', 'launch', 'visual', 'radio', 'servic', 'mobil', 'would', 'launch', 'europ', 'earli', 'year', 'servic', 'let', 'peopl', 'listen', 'radio', 'mobil', 'download', 'relev', 'content', 'like', 'track', 'rington', 'simultan', 'servic', 'design', 'make', 'mobil', 'radio', 'interact', 'among', 'new', 'product', 'showcas', 'digit', 'media', 'hub', 'big', 'upgrad', 'hp', 'digit', 'entertain', 'centr', 'come', 'autumn', 'us', 'box', 'network', 'highdefinit', 'tv', 'cabl', 'settop', 'box', 'digit', 'video', 'record', 'dvd', 'record', 'remov', 'hard', 'drive', 'cartridg', 'memori', 'card', 'slot', 'light', 'scribe', 'label', 'softwar', 'let', 'peopl', 'design', 'print', 'customis', 'dvd', 'label', 'cover', 'design', 'contain', 'household', 'digit', 'media', 'prerecord', 'tv', 'show', 'pictur', 'video', 'music', 'manag', 'one', 'place', 'hub', 'reflect', 'increas', 'move', 'rebox', 'pc', 'work', 'part', 'key', 'centr', 'entertain', 'research', 'suggest', '258', 'million', 'imag', 'save', 'share', 'everi', 'day', 'equat', '94', 'billion', 'year', 'eighti', 'per', 'cent', 'remain', 'camera', 'media', 'hub', 'design', 'encourag', 'peopl', 'organis', 'one', 'box', 'ms', 'fiorina', 'one', 'sever', 'keynot', 'speaker', 'also', 'includ', 'microsoft', 'chief', 'bill', 'gate', 'set', 'major', 'technolog', 'compani', 'think', 'peopl', 'technolog', 'gadget', 'next', '12', 'month', 'separ', 'announc', 'keynot', 'speech', 'ms', 'fiorina', 'said', 'hp', 'would', 'partner', 'mtv', 'replac', 'year', 'mtv', 'asia', 'music', 'award', 'mtv', 'asia', 'aid', 'held', 'bangkok', '3', 'februari', 'aim', 'help', 'rais', 'money', 'asian', 'tsunami', 'disast']\n"
     ]
    }
   ],
   "source": [
    "print(example[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91feee16",
   "metadata": {},
   "source": [
    "**Lemmatisation**\n",
    "\n",
    "Lemma is the canonical form dictionary form, or citation form of a set of word forms. In English, for example, break, breaks, broke, broken, and breaking are forms of the same lexeme, with break as the lemma by which they are indexed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18e6f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christopherreid/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d88d00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            --Lemma--           \n",
      "program             program             program             \n",
      "programming         program             program             \n",
      "programmer          programm            programmer          \n",
      "programs            program             program             \n",
      "programmed          program             program             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/christopherreid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize Python porter stemmer\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Example inflections to reduce\n",
    "example_words = ['program', 'programming', 'programmer', 'programs', 'programmed']\n",
    "\n",
    "# Perform stemming\n",
    "print('{0:20}{1:20}{2:20}'.format('--Word--', '--Stem--', '--Lemma--'))\n",
    "for word in example_words:\n",
    "    print('{0:20}{1:20}{2:20}'.format(word, ps.stem(word), wnl.lemmatize(word, pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b0d197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ebc349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['text lemma'] = articles_df['stopwords_removed'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "449e4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0aabe2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>text lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>sport</td>\n",
       "      <td>ireland 19-13 england ireland consigned englan...</td>\n",
       "      <td>ireland 19-13 england ireland consigned englan...</td>\n",
       "      <td>ireland 1913 england ireland consigned england...</td>\n",
       "      <td>[ireland, 1913, england, ireland, consigned, e...</td>\n",
       "      <td>[ireland, 1913, england, ireland, consigned, e...</td>\n",
       "      <td>[ireland, 1913, england, ireland, consign, eng...</td>\n",
       "      <td>[ireland, 1913, england, ireland, consigned, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               text                                         lower_case  \\\n",
       "801    sport  ireland 19-13 england ireland consigned englan...  ireland 19-13 england ireland consigned englan...   \n",
       "\n",
       "                                         punct_removed                                          tokenized  \\\n",
       "801  ireland 1913 england ireland consigned england...  [ireland, 1913, england, ireland, consigned, e...   \n",
       "\n",
       "                                     stopwords_removed                                   snowball_stemmer  \\\n",
       "801  [ireland, 1913, england, ireland, consigned, e...  [ireland, 1913, england, ireland, consign, eng...   \n",
       "\n",
       "                                            text lemma  \n",
       "801  [ireland, 1913, england, ireland, consigned, e...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa3fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
